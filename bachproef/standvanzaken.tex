\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}
\label{ch:stand-van-zaken}
Dit deel begint met een inleiding over virtualisatie, de redenen om aan virtualisatie te doen en de verschillende soorten. Hiertoer worden eerst Virtuele machines en Hypervisors besproken. Dit wordt gevolgd door een geschiedenis van het ontstaan van container virtualisatie en de effectieve werking van ervan, om vervolgens een vergelijking te schetsen tussen Virtuele machines en Container virtualisatie. Dit deel wordt afgesloten met het overlopen van de gevonden aanbieders van software voor container virtualisatie, die in de rest van de bachelorproef zouden kunnen worden getest.

% Tip: Begin elk hoofdstuk met een paragraaf inleiding die beschrijft hoe
% dit hoofdstuk past binnen het geheel van de bachelorproef. Geef in het
% bijzonder aan wat de link is met het vorige en volgende hoofdstuk.

% Pas na deze inleidende paragraaf komt de eerste sectiehoofding.
\section{Wat is virtualisatie}

Virtualisatie is in essentie het maken van een abstractie van de onderliggende hardware waarop de software berust tijdens het uitvoeren van processen. Naast de hardware laat virtualisatie ook toe om het besturingssysteem waarmee de software de hardware aanspreekt naar de hand te zetten. Een eerste reden om aan virtualisatie te doen is om mogelijke verschillen in hardware en besturingssystemen uit te sluiten. Software die ontwikkeld wordt in een omgeving met een zekere hardware en besturingssysteem kan zich anders gedragen of zelfs incompatibel zijn met de omgeving waarin de software effectief in productie gebruikt moet worden. Een verder voordeel van virtualisatie is dat het een betere benutting van hardware toelaat, zeker bij servers. De fysieke hardware van een server kan door middel van virtualisatie gebruikt worden om meerdere applicaties draaien die elk totaal andere vereisten hebben. Ook hier helpt de abstractie van de oorspronkelijke hardware en eventuele besturingssysteem van de server een gebruiker die software wilt draaien op een server zonder de hardware van de server te moeten kennen\Autocite{Yadav2018,Jangla2018}.

Voor virtualisatie bestaan er verschillende manieren van aanpak. Een eerste is de virtuele machine manier wat in het volgend deel besproken wordt. Een tweede manier bestaat er in om de virtualisatie van software te beheren op een analoge wijze als vrachtcontainers. Ten derde is er ook nog emulatie, een vorm van virtualisatie die niet verder behandeld wordt in deze thesis.

\section{Virtuele machines en Hypervisors}

\subsection{Virtuele machines}
Een eerste manier van virtualisatie is een volledige Virtuele Machine (VM). Bij een VM wordt er virtuele hardware voorzien van een eigen besturingssysteem. Aan de hand van dit besturingssysteem en de virtuele hardware is het dan ook mogelijk om in deze VM een applicatie te draaien alsof hij op een echte machine staat. Verder zorgt deze virtualisatie ervoor dat het draaien van een applicatie in een VM volledig hetzelfde zal blijven zelfs al zou de VM zelf op andere hardware berusten. Het besturingssysteem dat in de VM draait is volledig configureerbaar waardoor het mogelijk is om andere soorten toestellen na te bootsen, zoals een gsm. Een VM zelf is niets meer dan de ruimte op de opslagschijf die het gebruikt om zijn eigen instellingen en zijn eigen interne bestanden te bewaren. Wegens de aanwezigheid van een volledige besturingssysteem kan de geheugenruimte die een VM inneemt echter groot zijn. Het direct aanspreken van bestanden in het interne geheugen van een VM langs buitenaf zonder via de VM’s kanalen te werken is ook standaard niet mogelijk\autocite{Eder2016}.

\subsection{Hypervisors}

Omdat een VM beschouwd kan worden als gewoon een deel van het geheugen dat gebruikt wordt om het op te slaan is er nood aan bijkomende software om de VM effectief bruikbaar te maken. Deze bijkomende software wordt een Hypervisor genoemd. De Hypervisor staat voornamelijk in voor het vertalen van de input die de VM naar zijn eigen virtuele hardware stuurt en het omzetten hiervan zodat ze door de werkelijke hardware uitgevoerd kunnen worden. De virtuele kernel van de VM wordt dus dankzij de hypervisor effectief uitgevoerd. Een Hypervisor beperkt zich niet tot het beheren van maar één VM, het laat ook toe om nieuwe VM’s aan te maken door middel van het alloceren van de nodige geheugenruimte en het voorbereiden van de virtuele hardware om een besturingssysteem op te zetten. Aansluitend laat de Hypervisor dan ook toe dat er meerdere VM’s tegelijkertijd in gebruik kunnen worden genomen. Vaak laat een hypervisor ook toe om op een eenvoudige manier de VM van buitenaf te bereiken. Hetzij door een bestandslocatie te voorzien die je zowel via de VM als van buiten af kunt bereiken of door het klaarzetten van virtuele netwerken waarmee de verschillende VM’s onderling of naar buiten kunnen communiceren.

Onder Hypervisors zijn er twee verschillende types te onderscheiden. Type 1 Hypervisors staan zelf direct op de hardware van de machine. Hierdoor heeft de hardware geen directe besturingssysteem, en spreekt de hypervisor direct de machine kernel aan voor de uitvoering van opdrachten. Zo zijn de aanwezige besturingssystemen enkel deze die als gast door de Hypervisor in een VM worden uitgevoerd op de hardware. Type 2 Hypervisors daarentegen worden uitgevoerd als een gebruikers applicatie binnen een host besturingssysteem. De VM’s draaien genest in een conventioneel besturingssysteem en een omgeving die gebruikt kan worden. Het verschil tussen de twee wordt geïllustreerd in figuur \ref{fig:hyperviors} \autocite{Yadav2018,Eder2016}.

\begin{figure}[h]
    \includegraphics[width=\linewidth]{img/hypervisors.jpg}
    \caption[Verschil tussen type 1 en type 2 hypervisor]{Deze figuur toont het verschil tussen de locatie van de hypervisor en zijn VM’s ten opzichte van de hardware.}
    \label{fig:hyperviors}
    \centering
\end{figure}

\section{Container virtualisatie}

Bij container virtualisatie is de kerngedachte om enkel te virtualiseren wat de applicatie effectief nodig heeft. De applicatie zelf en alle dependencies die het nodig heeft worden gebundeld in een ‘container’ die overal kan worden gebruikt. In deze vorm van virtualisatie wordt de hardware en besturingssysteem niet volledig gevirtualiseerd, de containers spreken zelf het besturingssysteem van de host aan om procestijd en andere hardware middelen te vragen. Doordat het beeld, ook image genoemd, van een container minder data bijhoudt dan dat van een VM zijn ze kleiner en starten ze sneller op\autocite{Eder2016,Jangla2018}.

\subsection{Korte geschiedenis van container virtualisatie}

Een oudere manier van container virtualisatie bestaat al lang in de vorm van de \textbf{ch}ange \textbf{root} functionaliteit in Unix gebaseerde besturingssystemen. Met chroot is het sinds 1982 mogelijk om de root directory van een proces, en zijn sub processen, aan te passen en zo te beperken waartoe het proces toegang heeft. Vanuit chroot is het Linux containers (LXC) project gestart en werd het in 2008 mogelijk om op Linux gebaseerde container virtualisatie te doen via de ontwikkelde toolkit. Met deze toolkit is het iets eenvoudiger om containers te maken maar is er toch nog veel kennis van de Linux kernel nodig\autocite{Eder2016,SenthilKumaran2017}.

In 2013 kwam Docker op de markt, die erin slaagde om het werken met Linux gebaseerde containers veel te vereenvoudigen ten opzichte van LXC’s toolkit\autocite{Hykes2013}. Door Docker’s succes in het vereenvoudigen van de workflow voor het creëren en draaien van containers is deze technologie dan ook in een versnelling terecht gekomen. Eén van de grote vernieuwingen die Docker zelf bracht was het werken met duidelijke container images voor het maken en bewaren van containers. Hierbij biedt Docker ook de Docker hub aan om deze images te bewaren en te delen. Dockers succes werd verder ondersteund doordat Google al zelf een tijd intern werkte met containers en zo geschikte software kon aanbieden om gebruiksvriendelijk meerdere containers tegelijkertijd te beheren. In 2016 publiceerde Google een retrospectieve die uitgelegde hoe het al een aantal jaren met Linux gebaseerde containers werkte door middel van oudere software Borg en Omega, en hiermee Kubernetes ontwikkelde. De gebruiksvriendelijkheid en voordelen die deze lichtere vorm van virtualisatie kan bieden zorgden er dan ook voor dat container virtualisatie door velen werd geadopteerd \autocite{Eder2016}.

\subsection{Engine}

Voor het aanmaken en draaien van containers op een systeem is er nood aan een container manager of engine. Met een container engine is het mogelijk om een container image te maken, op te starten en te beheren. Het effectief draaien van de container wordt gedaan aan de hand van een runtime die vaak gebundeld zit in de engine. De bijkomende functionaliteiten zijn eigen aan de engine. De werking van containers word getoond in figuur \ref{fig:Containers}. De levenscyclus van een container door een engine begint met het ophalen van een container image om van te vertrekken. Deze kunnen gedownload worden van een publieke of privé repository van images. Dit vertrekpunt kan dan verder worden aangepast voor de specifieke applicatienoden vooraleer terug opgeslagen te worden in nieuwe image. Hierna kan de image worden gebruikt om een container te starten. Op basis van eenzelfde image kunnen gelijktijdig meerdere containers worden gestart. Containers hebben ook de mogelijkheid om data weg te schrijven naar een externe volume zodanig dat deze gegevens niet verloren gaan bij het stoppen van een container. Het beheren en toekennen van deze volumes behoort ook tot de functionaliteiten van de engine. Een container engine kan software zijn die on-premise geïnstalleerd is, waardoor de configuratie zelf te doen is, of het kan worden aangeboden door een Cloud service provider, zodat er in deze Cloud omgeving zonder te veel configuratieinspanningen vlot met containers kan worden gewerkt\autocite{Casalicchio2020}.
\begin{figure}[h]
    \includegraphics[width=\linewidth]{img/container.jpg}
    \caption[Schema container virtualisatie]{Een schematische voorstelling van container virtualisatie}
    \label{fig:Containers}
    \centering
\end{figure}

\subsection{Orchestration}
Om grotere hoeveelheden diverse container applicaties te kunnen beheren is er Container Orchestration software. Orchestration is vooral gericht naar het beheren van Multi-level applicaties waarvan de delen in containers draaien. Met orchestration software kan er eenvoudiger geconfigureerd worden hoe verschillende container applicaties met elkaar moeten verbinden en is het zelfs mogelijk om deze communicatie tussen container applicaties over meerdere fysieke servers te spreiden. Ander functionaliteiten die dit soort software vaak hebben is het beheren van fouttolerantie en het opschalen van aanbod. Hiermee kan er bij toenemende nood aan container applicaties door een stijgende gebruiksvraag of bij de plotse uitval van een container, extra containers aangemaakt worden en opgestart worden in het systeem. Ook voor orchestration bestaat er een onderscheid tussen on-premise software, of orchestration als deel van het aanbod van een Cloud service provider die container ondersteuning biedt\autocite{Casalicchio2020,Truyen2019}.


\section{Verschillen tussen virtuele machines en containers}
Het voornaamste verschil tussen Container virtualisatie en de VM+hypervisor virtualisatie is de afwezigheid van volwaardige besturingssystemen bij containers. De applicaties in een VM zijn ook meer geïsoleerd door de volledige virtualisering van de hardware. Containers daarentegen zijn kleiner dan VMs en bijkomend minder goed geïsoleerd waardoor risico’s toenemen. figuur \ref{fig:containerVShypervisor} toont schematisch de verschillen.

\begin{figure}[h]
    \includegraphics[width=\linewidth]{img/containerVShyper.jpg}
    \caption[Vergelijking container virtualisatie en type 1 hypervisor]{Een vergelijking in werking tussen container virtualisatie en een type 1 hypervisor voor het draaien van apps.}
    \label{fig:containerVShypervisor}
    \centering
\end{figure}

\subsection{Performantie verschillen}
Een vergelijkende studie tussen Containers en virtuele machine gebaseerde virtualisatie\autocite{Yadav2018} haalt aan dat de verschillende manieren van virtualisatie elk hun voordelen en nadelen hebben en dat het juiste gebruik ervan afhangt van de noden van de huidige situatie. Dit onderzoek haalt enkele voordelen aan die containers hebben ten opzichte van VM’s zoals: minder nood aan geheugenruimte, snellere boot-up en hogere draagbaarheid van containers. Maar het wijst er ookop dat de beveiliging bij containers moeilijker is doordat containers direct de host kernel en hardware aanspreken. In een Cloud omgeving zullen zowel VM’s als container virtualisatie hun plaats hebben. Zo zijn VM’s beter geschikt voor een Interface as a Service Cloud oplossing of situaties waar beveiliging van zeer hoog belang is, terwijl Containers meer toepasbaar zijn voor Software as a Service.

Een gelijkaardige studie door \textcite{Eder2016} komt tot gelijkaardige conclusies. VM’s en hypervisors vormen een extra laag beveiliging bij virtualisatie. Containers hebben dan weer het voordeel van sneller en eenvoudiger te zijn waardoor ze zeer toepasbaar zijn in een Cloud omgeving.

Een recent onderzoek van \textcite{Abdullah2019} heeft vooral gezocht naar de verschillen in opschalen van multi-level applicaties in een container of VM gebaseerd netwerk. Zij concludeerden dat container-based virtualisatie beter is om een snel toenemende vraag aan te kunnen.


\section{Software aanbieders}
In dit deel komen verschillende software pakketten en aanbieders van software voor container virtualisatie aan bod. Hiertoe wordt eerst uitgelegd hoe er een standaard voor containers gedefinieerd werd, gevolgd door software voor runtimes, engines, container types en orchestration. Hierna komen de verschillende aanbieders van platformen voor het hosten en delen van container images aan bod. Tenslotte bespreken we enkele grote Cloud service providers en hun ondersteuning voor containers in hun Cloud omgeving.


\subsection{Open Container Initiative}
Om de onderlinge werking en overdraagbaarheid tussen alle mogelijke software te waarborgen is het Open Container Initiative(OCI)\footnote{\url{https://opencontainers.org/}} tot stand gebracht. Het OCI legt twee standaarden op. De eerste standaard is de runtime specificatie voor het draaien van containers. De tweede standaard is voor het bewaren van de image van een container.


\subsection{Engines en runtimes}
Er bestaan meerdere engines en runtimes voor containers. De meerderheid is bedoeld om Linux gebaseerde, en daar mee OCI-compliant, containers te draaien. Maar er bestaan ook andere soorten containers die ook in dit deel van de thesis worden besproken.

\paragraph{Docker engine}
De runtime en daemon waarmee Docker werkt heet de Docker engine. De daemon zelf is gebaseerd op Containerd wat hierna besproken wordt. Het werkt via een Command-line-interface (CLI) om zolang dat de daemon draait containers te kunnen starten, aanmaken of verwijderen. . Het laat ook toe huidige containers aan te spreken en hun status op te halen. De Docker engine word voor Mac os en Windows gebundeld met de Docker desktop, een user interface om de werking van de engine te beheren zonder via de CLI te moeten werken. De Docker engine is dan ook bruikbaar op alle vaak voorkomende besturingssystemen, maar Linux distributies hebben momenteel geen toegang tot de Docker desktop.
\paragraph{Containerd}
Containerd\footnote{\url{https://containerd.io/}} is een industriestandaard runtime om op Linux en Windows systemen containers te draaien. Door middel van Go programma’s kan Containerd een container image pullen, configureren, opstarten en beëindigen.
\paragraph{Linux containers}
Zoals eerder aangehaald zijn Linux containers een manier om met containers te werken op Linux. Het vergt echter veel kennis van de Linux kernel om deze goed te kunnen gebruiken. Het omvat zowel de LXC manier om containers te maken en draaien, als een uitbreiding van LXC onder de vorm van LXD. LXC is standaard inbegrepen als deel van veel van de Linux distributies. 
\paragraph{CRI-O}
Cri-o\footnote{\url{https://cri-o.io/}} is een engine die zichzelf verkoopt als een lichter alternatief voor de Docker engine. Het is ook vooral gericht naar integratie met Kubernetes en heeft bijgevolg niet de ingesteldheid om direct aangesproken te kunnen worden door een gebruiker.
\paragraph{Podman}
Podman\footnote{\url{https://podman.io/}} is een CLI om Linux containers te creëren, draaien en stoppen op een Linux systeem. Het lijkt doelbewust veel op Docker maar heeft een paar verschillen. Zo werkt het zonder een deamon die beheerd moet worden voor het uitvoeren van containers, en heeft het ook een ingebouwde ondersteuning om meerdere containers samen te bundelen in een “pod” en deze in een geheel te beheren.
\paragraph{Windows containers}
Windows containers\footnote{\url{https://docs.microsoft.com/en-us/virtualization/windowscontainers/about/}} is een specifieke runtime om op Windows gebaseerde containers uit te voeren. Het heeft geen eigen engine en berust op integratie met Docker engine en de Docker desktop voor de verdere functionaliteiten. Het draaien van Windows containers is mogelijk op de Server, Enterprise of Education edities van Windows.
\paragraph{Pouch containers}
Pouch containers\footnote{\url{https://pouchcontainer.io/}} is een open source engine voor Linux containers gestart door de Alibaba Group\footnote{\url{https://www.alibabagroup.com/en/global/home}}. Het ondersteunt Linux als besturingssysteem en werkt via een CLI. Het is ook OCI-compliant. De laatste stabiele release ten tijde van dit onderzoek was in juni 2019.
\paragraph{Kata containers}
Kata containers\footnote{\url{https://katacontainers.io/}} combineert de beveiligingsvoordelen van VM met de draagbaarheid van containers. Zo heeft het ook zijn eigen indeling voor container images. Het is een open source runtime en berust op een andere engine voor de engine functionaliteiten zoals CRI-O en Containerd. Het kan gebruikt worden op vele Linux distributies.
\paragraph{Andere engine opties}
De volgende opties voor runtimes of engines engines worden niet meer goed ondersteund.
\begin{itemize}
    \item Open vz\footnote{\url{https://openvz.org/}}: Een open source Linux zowel containers als virtuele machines te draaien, verdere ontwikkeling vertoont slechts weinig activiteit sinds 2015.
    \item Rkt\footnote{\url{https://www.openshift.com/learn/topics/rkt}}: Linux containers die na een RedHat acquisitie niet meer ondersteund wordt, laatste release was 2018.
    \item Balena engine\footnote{\url{https://github.com/balena-os/balena-engine}}: Een specifieke engine voor Internet of Things toepassingen met een laatste release in December 2019.
    \item Flockport\footnote{\url{https://www.flockport.com/}}: Een open source engine met ook wat orchestration functionaliteiten voor enkele van de meest voorkomende Linux distributies. De open source is niet terug te vinden en er is bijna geen activiteit meer op de officiële website sinds 2019 ten tijde van dit onderzoek.
\end{itemize}


\subsection{Orchestration}
Orchestration is een belangrijk deel van de Cloud mogelijkheden van containers er zijn dan ook verschillende aanbieders van software om dit te organiseren. Sommige orchestration software is specifiek voor containers, maar andere software laat ook toe om de container orchestration te bundelen met de orchestration voor andere processen zoals klassieke VMs. Voor containers is Kubernetes het meest gekende orchestrations software en volgens onderzoek van \textcite{Truyen2019}, ook de software met de meeste features. 
\paragraph{Docker Compose en Swarm}
Docker Compose is een eerste deel van de orchestration die deel uitmaakt van Dockers totaalpakket. Het staat in voor het regelen van applicaties die uit meerdere delen bestaan, die elk in een eigen container draaien zolang ze behoren tot één Docker engine. Een voorbeeld hiervan is een webapplicatie zoals Wordpress met een aparte container voor de SQL-databank. Docker Compose laat een gebruiker toe om via een YAML-configuratiebestand meerdere containers aan elkaar te verbinden en ze later gezamenlijk op te starten en stoppen.

Docker Swarm is het orchestration gedeelte bedoeld om over meerdere aparte instanties van Docker engines te werken en werkt ook via een CLI. Hierbij wordt elke instantie van een Docker engine beschouwd als een node binnen de “swarm” (zwerm). Er bestaan 2 soorten nodes binnen een Docker Swarm. Manager nodes staan in voor het beheren en delegeren van taken binnen een swarm. De worker nodes voeren de taken uitgestuurd door een manager uit. Standaard is een manager ook een worker maar dit kan uitgezet worden. Om een swarm te hebben moet een engine instantie de swarm initiëren en moeten andere eventuele engines zichzelf toevoegen. Via een manager node kunnen de orchestration instellingen dan gepropageerd worden over de rest van de manager nodes en uitgevoerd door de worker nodes.
\paragraph{Kubernetes}
Kubernetes\footnote{\url{https://kubernetes.io/}} is een open source orchestration software die container orchestration toelaat, onafhankelijk van de container runtime zolang die maar de Kubernetes CRI (Container Runtime Interface) implementeert. Het werkt met pods, sets van bij elkaar horende containers, die behoren tot een fysieke of virtuele machine die de mogelijkheid heeft om de pods te draaien. Elke van deze machines wordt een node genoemd. Elke node krijgt een kublet die instaat voor het organiseren van het draaien van de pods binnen een node. Daarnaast krijgt ook elke node een proxy om te communiceren met een control plane. De control plane beheert alle nodes in de cluster en kan op één machine staan of ook gedistribueerd zijn. Standaard werkt Kubernetes via de command line maar het biedt ook de mogelijkheid om een dashboard UI bij te installeren.
\paragraph{Red hat Openshift}
Openshift\footnote{\url{https://www.openshift.com/}} is Red Hat’s uitbreiding extensie van de Kubernetes software om dienst te doen als orchestration software. Openshift wilt toelaten om orchestration gelijktijdig te regelen over eigen on-premise servers en servers die van een Cloud service provider worden benut. Hier blijft niet enkel bij eigen servers en één Cloud service provider, het laat zelfs toe om de orchestration te doen over meerde Cloud service providers heen.
\paragraph{Nomad}
Nomad\footnote{\url{https://www.nomadproject.io/}} is een enterprise gefocuste orchestration software, aangeboden door HashiCorp, die ook gemengde orchestration op grote schaal toelaat. Het verkoopt zichzelf als een manier om met containers om te gaan als een vervanging of aanvulling van Kubernetes. Naast een CLI komt het standaard ook met een web User Interface om orchestration te regelen.
\paragraph{Apache Mesos}
Mesos\footnote{\url{http://mesos.apache.org/}} is een orchestration framework van Apache die grotere schaal orchestration toelaat. Naast containers biedt het ook ondersteuning om Virtuele machines te beheren. Het maakt een abstractie van de kernel over meerdere machines heen om zo in een server context orchestration te regelen.
\paragraph{DC/OS}
De Distributed Cloud Operating System\footnote{\url{https://dcos.io/}} is een open source besturingssysteem dat gebaseerd is op Apache Mesos om via een singuliere interface meerdere machines te bereiken, om zo orchestration van containers en meer over meerdere machines toe te laten.
\subsection{Image repositories}
Om container images te kunnen delen met anderen zijn er repositories beschikbaar die deze remote kunnen bewaren. Naast de drie repositories die hieronder besproken worden, bieden Cloud service providers ook hun eigen repositories aan voor intern gebruik binnen hun Cloud omgeving.
\paragraph{Docker Hub}
De Docker Hub\footnote{\url{https://hub.docker.com/}} is de grootste en meest gekende repository voor container images. Het heeft een grote bibliotheek aan images. Veel vaak gebruikte images worden dan ook gehost op de Docker Hub en Docker helpt ook bij het erkennen van officiële images. Voor het hosten van eigen images op de Docker zijn publieke images gratis. Een gratis account heeft de mogelijk om 1 repository private te zetten. De limieten op het pullen of pushen van images die tot een gratis account behoren zijn maximaal 100 anonieme en maximaal 200 ingelogde per zes uur. 
\paragraph{GitHub Container Registry}
GitHub werkt aan een functionaliteit om als gebruiker of onderneming op GitHub container images te bewaren, genaamd de  GitHub Container Registry\footnote{\url{https://docs.github.com/en/packages/guides/about-github-container-registry}}. Het ondersteunt zowel Docker’s eigen images als OCI images. Het is een deel van GitHub’s packages en is momenteel nog in bèta. De container registry wijkt af van de GitHub packages in die mate dat de container images niet gekoppeld moeten zijn met een Github repository. Hierdoor zijn de toegangsrechten van de images onafhankelijk van de eventuele repositories waartoe ze behoren en kunnen deze afzonderlijk ingesteld worden. Bijkomend is het mogelijk om een publiek gedeelde container image anoniem te downloaden, iets wat met gewone packages niet toegestaan is. Tijdens de bèta is het gebruik van de container registry volledig gratis. Eens het uit beta is zal de container registry samen met de rest van de GitHub packages gefactureerd worden. Namelijk publieke bestanden gratis, en een limiet op bestandsgrootte en data-overdracht voor private images.
\paragraph{GitLab Container Registery}
De GitLab Container Registry\footnote{\url{https://docs.gitlab.com/ee/user/packages/container_registry/}} is gebaseerd op de open source Docker  Registry. Het laat toe om per Gitlab project een locatie voor container images te voorzien. Voor het ophalen en uploaden van images werkt het met de Gitlab CLI. Het laat ook private en publieke images toe, in de vorm van overerving van de toegankelijkheid van het project waartoe de registry behoort.

\subsection{Cloud hosting en services}
De grootte Cloud hosting en service providers bieden elk ondersteuning voor containers aan en hebben niet veel verschillen.
\paragraph{Amazon AWS}
Als deel van Amazon’s Cloud services biedt het via AWS\footnote{\url{https://aws.amazon.com/}} toegang tot 3 container verwante services. De eerste is het Amazon Elastic Container Registry (ECR). Het ECR is specifiek voor het bewaren van container images en de toegangsconfiguratie tot de registry. De tweede is het Amazon Elastic Container Service (ECS). Het ECS staat in voor het uitvoeren van container gebaseerde applicaties op Amazon’s webhosting services aan de hand van Amazon’s eigen manier van orchestration. En de derde is het Amazon Elastic Kubernetes Service (EKS). Dit laat ook toe om container gebaseerde applicaties te draaien, maar dan met een Kubernetes gebaseerde aanpak voor het beheren en opschalen van de containers. Naast deze 3 specifieke services is het ook mogelijk om een container host te installeren op de generische Elastic Compute Cloud webhosting van AWS.
\paragraph{Microsoft Azure}
Microsoft’s Azure\footnote{\url{https://azure.microsoft.com/}} biedt ook ondersteuning voor containers met 3 primaire services die nauw lijken op de services van Amazon. Eerst is er de Azure Container Registry (ACR). Het ACR is de container registry methode van Azure. De tweede is de Azure Container Instances (ACI). Het ACI is analoog aan Amazon’s ECS voor het uitvoeren van containers en de bijhorende orchestration. Ten slotte biedt Azure ook Azure Kubernetes Services (AKS) aan. Het AKS is dan de manier om op Azure de Kubernetes gebaseerde aanpak te gebruiken. Ook hier is het naast deze services mogelijk om containers te hosten om Azure’s Web Apps hosting service.
\paragraph{Google Cloud}
Google’s Cloud\footnote{\url{https://cloud.google.com/}} zet de trend verder met hun Google Container Registry (GCR), Google Cloud Run (GCR) en Google Kubernetes Engine (GKE). Deze 3 services zijn elk analoog aan hun equivalenten in AWS en Azure. Ook in Google's Cloud is er de mogelijkheid om een container host te installeren op de algemene hosting service Google Compute Engine.
\paragraph{IBM Cloud}
De IBM Cloud\footnote{\url{https://www.ibm.com/cloud}} biedt ook ondersteuning voor containers. Zo heeft het ook een container registry en een kubernetes gebaseerde container hosting service.
\paragraph{Red Hat OpenStack}
Voor het werken over verschillende Cloud service providers met Openshift zijn er momenteel 4 Cloud providers die integratie met OpenShift hebben. Azure, IMB en AWS hebben een specifieke service voor OpenShift op hun systeem. Verder bieden Google Cloud en AWS de mogelijkheid om hun hardware te gebruiken om een niet direct met de provider gekoppelde instantie te hosten.



